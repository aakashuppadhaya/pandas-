{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = open('quandlapikey.txt','r').read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Since we'll wind up with 50 dataframes here, we'd rather combine them all into one massive one We will use join in this case because the data is returned back to us, using the Quandl module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FMAC/HPI_AL\n",
      "FMAC/HPI_AK\n",
      "FMAC/HPI_AZ\n",
      "FMAC/HPI_AR\n",
      "FMAC/HPI_CA\n",
      "FMAC/HPI_CO\n",
      "FMAC/HPI_CT\n",
      "FMAC/HPI_DE\n",
      "FMAC/HPI_FL\n",
      "FMAC/HPI_GA\n",
      "FMAC/HPI_HI\n",
      "FMAC/HPI_ID\n",
      "FMAC/HPI_IL\n",
      "FMAC/HPI_IN\n",
      "FMAC/HPI_IA\n",
      "FMAC/HPI_KS\n",
      "FMAC/HPI_KY\n",
      "FMAC/HPI_LA\n",
      "FMAC/HPI_ME\n",
      "FMAC/HPI_MD\n",
      "FMAC/HPI_MA\n",
      "FMAC/HPI_MI\n",
      "FMAC/HPI_MN\n",
      "FMAC/HPI_MS\n",
      "FMAC/HPI_MO\n",
      "FMAC/HPI_MT\n",
      "FMAC/HPI_NE\n",
      "FMAC/HPI_NV\n",
      "FMAC/HPI_NH\n",
      "FMAC/HPI_NJ\n",
      "FMAC/HPI_NM\n",
      "FMAC/HPI_NY\n",
      "FMAC/HPI_NC\n",
      "FMAC/HPI_ND\n",
      "FMAC/HPI_OH\n",
      "FMAC/HPI_OK\n",
      "FMAC/HPI_OR\n",
      "FMAC/HPI_PA\n",
      "FMAC/HPI_RI\n",
      "FMAC/HPI_SC\n",
      "FMAC/HPI_SD\n",
      "FMAC/HPI_TN\n",
      "FMAC/HPI_TX\n",
      "FMAC/HPI_UT\n",
      "FMAC/HPI_VT\n",
      "FMAC/HPI_VA\n",
      "FMAC/HPI_WA\n",
      "FMAC/HPI_WV\n",
      "FMAC/HPI_WI\n",
      "FMAC/HPI_WY\n"
     ]
    }
   ],
   "source": [
    "def state_list():\n",
    "    fiddy_states = pd.read_html('https://simple.wikipedia.org/wiki/List_of_U.S._states')\n",
    "    return fiddy_states[0][0][1:]\n",
    "    \n",
    "\n",
    "def grab_initial_state_data():\n",
    "    states = state_list()\n",
    "\n",
    "    main_df = pd.DataFrame()\n",
    "\n",
    "    for abbv in states:\n",
    "        query = \"FMAC/HPI_\"+str(abbv)\n",
    "        df = quandl.get(query, authtoken=api_key)\n",
    "        df.rename(columns={'Value':str(abbv)}, inplace=True)#its done because of value error\n",
    "        print(query)\n",
    "        if main_df.empty:\n",
    "            main_df = df\n",
    "        else:\n",
    "            main_df = main_df.join(df)\n",
    "   \n",
    "    \n",
    "grab_initial_state_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When it comes to something like, machine learning, for example. You generally train a classifier, and then you can start immediately, and quickly, classifying with that classifier. The problem is, a classifer can't be saved to a .txt or .csv file. It's an object. Luckily, in programming, there are various terms for the process of saving binary data to a file that can be accessed later. In Python, this is called pickling. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First we open a .pickle file with the intention to write some bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle_out = open('fiddy_states.pickle','wb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Then, we do pickle.dump to dump the data we want to pickle, and then where to dump it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(main_df, pickle_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Finally, just any file, we close. Done, we've saved the pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "   pickle_out.close()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# to get the dataset back into pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Value          AK\n",
      "Date                              \n",
      "1975-01-31   35.303417   35.303417\n",
      "1975-02-28   35.502507   35.502507\n",
      "1975-03-31   35.734654   35.734654\n",
      "1975-04-30   36.015829   36.015829\n",
      "1975-05-31   36.267298   36.267298\n",
      "1975-06-30   36.372099   36.372099\n",
      "1975-07-31   36.278301   36.278301\n",
      "1975-08-31   36.043457   36.043457\n",
      "1975-09-30   35.805515   35.805515\n",
      "1975-10-31   35.718557   35.718557\n",
      "1975-11-30   35.855846   35.855846\n",
      "1975-12-31   36.222559   36.222559\n",
      "1976-01-31   36.782419   36.782419\n",
      "1976-02-29   37.411304   37.411304\n",
      "1976-03-31   37.947397   37.947397\n",
      "1976-04-30   38.293876   38.293876\n",
      "1976-05-31   38.471992   38.471992\n",
      "1976-06-30   38.559661   38.559661\n",
      "1976-07-31   38.635547   38.635547\n",
      "1976-08-31   38.700458   38.700458\n",
      "1976-09-30   38.740612   38.740612\n",
      "1976-10-31   38.800182   38.800182\n",
      "1976-11-30   38.938304   38.938304\n",
      "1976-12-31   39.092101   39.092101\n",
      "1977-01-31   39.167254   39.167254\n",
      "1977-02-28   39.190582   39.190582\n",
      "1977-03-31   39.231008   39.231008\n",
      "1977-04-30   39.397902   39.397902\n",
      "1977-05-31   39.720808   39.720808\n",
      "1977-06-30   40.161711   40.161711\n",
      "...                ...         ...\n",
      "2015-04-30  125.604009  125.604009\n",
      "2015-05-31  126.636958  126.636958\n",
      "2015-06-30  127.498822  127.498822\n",
      "2015-07-31  127.959223  127.959223\n",
      "2015-08-31  127.959320  127.959320\n",
      "2015-09-30  127.487775  127.487775\n",
      "2015-10-31  126.901296  126.901296\n",
      "2015-11-30  126.421380  126.421380\n",
      "2015-12-31  126.160407  126.160407\n",
      "2016-01-31  126.444334  126.444334\n",
      "2016-02-29  127.285665  127.285665\n",
      "2016-03-31  128.426049  128.426049\n",
      "2016-04-30  129.819410  129.819410\n",
      "2016-05-31  131.174429  131.174429\n",
      "2016-06-30  132.247811  132.247811\n",
      "2016-07-31  133.025705  133.025705\n",
      "2016-08-31  133.316306  133.316306\n",
      "2016-09-30  133.081297  133.081297\n",
      "2016-10-31  132.363681  132.363681\n",
      "2016-11-30  131.560770  131.560770\n",
      "2016-12-31  131.118937  131.118937\n",
      "2017-01-31  131.290319  131.290319\n",
      "2017-02-28  132.244567  132.244567\n",
      "2017-03-31  133.830220  133.830220\n",
      "2017-04-30  135.607889  135.607889\n",
      "2017-05-31  136.972678  136.972678\n",
      "2017-06-30  137.546538  137.546538\n",
      "2017-07-31  137.384042  137.384042\n",
      "2017-08-31  137.001692  137.001692\n",
      "2017-09-30  136.068609  136.068609\n",
      "\n",
      "[513 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pickle_in = open('fiddy_states.pickle','rb')\n",
    "HPI_data = pickle.load(pickle_in)\n",
    "print(HPI_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
